---
title: "Cluster size and VI"
date: 2019-1-28
output: pdf_document
---

# Does k affect VI?  

```{R include = FALSE}
library(knitr)
vi = function(x){
  # input: x = nx2 matrix; 1st column first cluster id (1 to k1);
  #            2nd column is the second clustering id (1 to k2)
  n <- dim(x)[1]
  klabels1 <- unique(x[,1])
  klabels2 <- unique(x[,2])
  k1 <- length(klabels1)
  k2 <- length(klabels2)
  # compute the k1 x k2 confusion matrix
  C <- matrix(0,k1,k2)
  for (j1 in klabels1){
    for (j2 in klabels2){
      C[j1,j2] <- sum((x[,1]==j1 & x[,2]==j2)*1)
    }
  }
  p1 <- apply(C,1,sum)/n # compute marginal probabilities
  p2 <- apply(C,2,sum)/n
  H1 <- -sum(na.omit(p1*log(p1)))
  H2 <- -sum(na.omit(p2*log(p2)))
  C <- C/n  
  ICC <- 0
  for (j1 in klabels1){
    for (j2 in klabels2){
      inc <- 0
      if (C[j1,j2] != 0){inc <-C[j1,j2]*log(C[j1,j2]/(p1[j1]*p2[j2]))}
      ICC <- ICC + inc
    }
  }
  vi <- H1 + H2 - 2*ICC
  return(vi)
}

```


Previously, we applied k-means to divide the variables into 4 groups. Does 4 is a good number to get a good match? 

I would like to try how much the number of clusters may affect VI

```{R}
# the known cluster A:
A = rep(1:4,each = 100)

# the other clustering results, 
# (i.e. what will happen if we cluster A into k groups)
B = rep(1:2,each = 200)
C = c(1,rep(1:3,each = 133))
D = rep(1:4, each = 100)
E = rep(1:5, each = 80)
f = c(rep(1:6, each = 66),1:4)
G = rep(1:10,each = 40)
H = rep(1:20, each = 20)

vi_random = c()
# Run 1000 times to get a range of VI
vi_random_B = c();vi_random_C = c();vi_random_D = c();vi_random_E = c();
vi_random_F = c();vi_random_G = c();vi_random_H = c()
for(i in 1:1000){
  vi_random_B = c(vi_random,vi(cbind(A,sample(B))))
  vi_random_C = c(vi_random,vi(cbind(A,sample(C))))
  vi_random_D = c(vi_random,vi(cbind(A,sample(D))))
  vi_random_E = c(vi_random,vi(cbind(A,sample(E))))
  vi_random_F = c(vi_random,vi(cbind(A,sample(f))))
  vi_random_G = c(vi_random,vi(cbind(A,sample(G))))
  vi_random_H = c(vi_random,vi(cbind(A,sample(H))))
}

# The results
range_vi = c()
range_vi = rbind(range_vi,range(vi_random_B))
range_vi = rbind(range_vi,range(vi_random_C))
range_vi = rbind(range_vi, range(vi_random_D))
range_vi = rbind(range_vi, range(vi_random_E))
range_vi = rbind(range_vi, range(vi_random_F))
range_vi = rbind(range_vi,range(vi_random_G))
range_vi = rbind(range_vi, range(vi_random_H))

vis = c(vi(cbind(A,B)),vi(cbind(A,C)),vi(cbind(A,D)),vi(cbind(A,E)),
vi(cbind(A,f)),vi(cbind(A,G)),vi(cbind(A,H)))
```

```{R echo = FALSE}
res = cbind(vis, range_vi)
colnames(res) = c('match', 'min random', 'max random')
rownames(res) = paste('k = ',c(2,3,4,5,6,10,20))
(kable(res))
```
 
Therefore the VI can be different, in different range. So how could we make them comparable?

 
# Unadjusted VI


Previously, we applied k-means to divide the variables into 4 groups. Does 4 is a good number to get a good match? 

To figure it out, I then change k from 2 to 10. Here are some results.


## One variable

I then only chose one continuous variable and cluster subjects based on this variable into k groups (k = 2,3,...10). The results:

```{R include = FALSE}

unfactorize = function(df){
  for(i in which(sapply(df, class) == "factor")){
    df[[i]] = as.character(df[[i]])
  } 
  return(df)
}

library(knitr)

vi = function(x){
  # input: x = nx2 matrix; 1st column first cluster id (1 to k1);
  #            2nd column is the second clustering id (1 to k2)
  n <- dim(x)[1]
  klabels1 <- unique(x[,1])
  klabels2 <- unique(x[,2])
  k1 <- length(klabels1)
  k2 <- length(klabels2)
  # compute the k1 x k2 confusion matrix
  C <- matrix(0,k1,k2)
  for (j1 in klabels1){
    for (j2 in klabels2){
      C[j1,j2] <- sum((x[,1]==j1 & x[,2]==j2)*1)
    }
  }
  p1 <- apply(C,1,sum)/n # compute marginal probabilities
  p2 <- apply(C,2,sum)/n
  H1 <- -sum(na.omit(p1*log(p1)))
  H2 <- -sum(na.omit(p2*log(p2)))
  C <- C/n  
  ICC <- 0
  for (j1 in klabels1){
    for (j2 in klabels2){
      inc <- 0
      if (C[j1,j2] != 0){inc <-C[j1,j2]*log(C[j1,j2]/(p1[j1]*p2[j2]))}
      ICC <- ICC + inc
    }
  }
  vi <- H1 + H2 - 2*ICC
  return(vi)
}

### standardize vi value
### the formular in the paper: vi/(2(log(k))) 

library(cluster)
library(fpc)

setwd('/Users/yaolanqiu/Desktop/NYU/rotation/Rotation2/week1/first code')

# Read in demographic data
demdat <- read.csv("primary-n151.csv", header=T)
# read in the final hamd outcome data
newdat <- read.csv("longFormat_score17.csv", header=T)

# > dim(demdat)
# [1] 151  67
# > dim(newdat)
# [1] 2009    9

# delete the repeatation of subjects
newdata = newdat[,c(1,2,3,6,7,8,9)]
newdata = unique(newdata)
rownames(newdata) = NULL

dim(newdata) # 287 7 

# merge data
merged = merge(newdata,demdat,by = c('ProjectSpecificId',"site",
                                     "Stage1TX","Sex","age_evaluation"), 
               how = 'inner')
merged$trt = (merged$Stage1TX=="SER/CIT")*1+1
newdat$trt = (newdat$Stage1TX =="SER/CIT")*1+1

dim(merged) # 150 * 7

# how many NAs?
sapply(merged, function(x) sum(is.na(x)))


#### deal with k

setwd('/Users/yaolanqiu/Desktop/NYU/rotation/Rotation2/week2')

## function to find the members in each cluster with smallest VI
vi_selection = function(n, data, k){
  # n: number of variables
  # data: input data set
  data_temp = unfactorize(data[data$vi == min(data$vi),])
  cov_temp = as.character(data_temp[1,1:n])
  temp = data.frame(ProjectSpecificId = merged$ProjectSpecificId,
                    trt = merged$trt, merged[,cov_temp])
  colnames(temp) = c('ProjectSpecificId','trt',cov_temp)
  temp = na.omit(temp)
  km_temp = kmeans(temp[,3:dim(temp)[2]], k, nstart = 25)
  return(list(km = km_temp, data = temp))
}

## function for the table
cluster_summary_table = function(km, data){
  n_clus = length(unique(km$cluster))
  drg = c(); pbo = c(); tot = c()
  for(i in 1:n_clus){
    drg = c(drg, sum(data[which(km$cluster == i),]$trt == 2))
    pbo = c(pbo, sum(data[which(km$cluster == i),]$trt == 1))
    tot = c(tot, dim(data[which(km$cluster == i),])[1])
  }
  drg_pbo = rbind(drg,pbo)
  drg_pbo = rbind(drg_pbo, apply(drg_pbo,2,sum))
  drg_pbo = cbind(drg_pbo, apply(drg_pbo,1,sum))
  drg_pbo = data.frame(drg_pbo)
  rownames(drg_pbo) = c('Drug', 'Placebo', 'Total')
  colnames(drg_pbo) = c(paste('cluster',1:n_clus),'Total')
  return(drg_pbo)
}

cluster_score_plot = function(km, data,k){
  par(mfrow = c(2,(round(k/2)+1)))
  for(clus_num in 1:k){
    id = data[which(km$cluster == clus_num),1]
    newdat_temp = newdat[which(newdat$ProjectSpecificId %in% id),
                         c('ProjectSpecificId','week','score17','trt')]
    plot_temp = newdat_temp[newdat_temp$ProjectSpecificId == id[1],]
    plot(plot_temp$week,
         plot_temp$score17,
         type = 'l', xlab = 'week',ylab = 'score',
         ylim =c(0, max(newdat$score17,na.rm =TRUE)),
         col = plot_temp$trt[1], # black: pbo; red: drg 
         main = paste('cluster',clus_num,'score plot'))
    
    for(i in 2:length(id)){
      plot_temp = newdat_temp[newdat_temp$ProjectSpecificId == id[i],]
      lines(col = plot_temp$trt[1],
            plot_temp$week,
            plot_temp$score17)
    }
  }
  par(mfrow = c(1,1))
}

```



```{R echo = FALSE, comment=NA}
### one parameter

min_vi1 = c()

for(k in 2:10){
  # choose continuous variables

  print('************************************************************')
  print(paste('k = ',k))
  print('************************************************************')
  
  p = dim(merged)[2] 
  merged2 = merged
  covars = c()
  for(i in 2:p){
    if(class(merged[,i])=="integer" | class(merged[,i]) == "numeric"){
      if(length(unique(merged[,i]))>k){
        covars = c(covars, i)
      }
    }
  }
  merged2 = merged[,c(1,covars)]
  merged2$trt = merged$trt
  
  dim(merged2) # 150  47
  
  ## put into k-means and VI calculation
  # one parameters
  names1 = c();
  vi1 = c()
  for(i in 2:length(covars)){
    n_covs = i
    # print(names(merged2)[n_covs])
    names1 = c(names1,names(merged2)[n_covs])
    temp = data.frame(trt = merged2$trt, merged2[,n_covs])
    temp = na.omit(temp)
    km_temp= kmeans(temp[,2:dim(temp)[2]], k, nstart = 20)
    vi1 = c(vi1, vi(cbind(temp$trt, km_temp$cluster)))
  }
  one_parameter = data.frame(names = names1, vi = vi1)
  print("**** min vi ****")
  print(min(one_parameter$vi))
  min_vi1 = c(min_vi1,min(one_parameter$vi))
  res = vi_selection(1,one_parameter,k)
  print("**** the summary table ****")
  print(cluster_summary_table(res$km,res$data))
  print("*** p value of the summary table ***")
  print(fisher.test(cluster_summary_table(res$km,res$data)[1:2,1:k])$p.value)
}

```


## Two variables

I then  chose two continuous variables and cluster subjects based on this variable into k groups (k = 2,3,...10). The results:

```{R echo = FALSE, comment=NA}

min_vi2 = c()
### two parameter
for(k in 2:10){
  # choose continuous variables
  
  print('************************************************************')
  print(paste('k = ',k))
  print('************************************************************')
  
  p = dim(merged)[2] 
  merged2 = merged
  covars = c()
  for(i in 2:p){
    if(class(merged[,i])=="integer" | class(merged[,i]) == "numeric"){
      if(length(unique(merged[,i]))>k){
        covars = c(covars, i)
      }
    }
  }
  merged2 = merged[,c(1,covars)]
  merged2$trt = merged$trt
  
  dim(merged2) # 150  47
  
  ## put into k-means and VI calculation
  
  names2 = c();
  vi2 = c()
  for(i in 2:(length(covars)-1)){
    for(j in (i+1):length(covars)){
      n_covs = c(i,j)
      #print(names(merged2)[n_covs])
      names2 = rbind(names2,names(merged2)[n_covs])
      temp = data.frame(trt = merged2$trt, merged2[,n_covs])
      #print("****")
      #print(dim(temp))
      temp = na.omit(temp)
      #print(dim(temp))
      km_temp= kmeans(temp[,2:dim(temp)[2]], k, nstart = 25)
      vi2 = c(vi2, vi(cbind(temp$trt, km_temp$cluster)))
      }
  }
  two_parameter = data.frame(names1 = names2[,1], names2 = names2[,2], vi = vi2)
  
  print("**** min vi ****")
  print(min(two_parameter$vi))
  res = vi_selection(1,two_parameter,k)
  min_vi2 = c(min_vi2,min(two_parameter$vi))
  print("**** the summary table ****")
  print(cluster_summary_table(res$km,res$data))
  print("*** p value of the summary table ***")
  print(fisher.test(cluster_summary_table(res$km,res$data)[1:2,1:k])$p.value)
}
```



```{R include=FALSE}
names(min_vi1) = 2:10
min_vi1
```


```{R include=FALSE}
names(min_vi2) = 2:10
min_vi2
```


#### The summary table

One variable

```{R echo =FALSE}

names(min_vi1) = 2:10
kable(round(t(min_vi1),3))
```

Two variables

```{R echo =FALSE}
names(min_vi2) = 2:10
kable(round(t(min_vi2),3))
```


When k > 2, the vi is increasing. 

However, they are not comparable, since 

# Adjusted VI


## One variable

I then only chose one continuous variable and cluster subjects based on this variable into k groups (k = 2,3,...10). The results:


```{R echo = FALSE, comment=NA}
### one parameter

min_vi1 = c()

for(k in 2:10){
  # choose continuous variables

  print('************************************************************')
  print(paste('k = ',k))
  print('************************************************************')
  
  p = dim(merged)[2] 
  merged2 = merged
  covars = c()
  for(i in 2:p){
    if(class(merged[,i])=="integer" | class(merged[,i]) == "numeric"){
      if(length(unique(merged[,i]))>k){
        covars = c(covars, i)
      }
    }
  }
  merged2 = merged[,c(1,covars)]
  merged2$trt = merged$trt
  
  dim(merged2) # 150  47
  
  ## put into k-means and VI calculation
  # one parameters
  names1 = c();
  vi1 = c()
  for(i in 2:length(covars)){
    n_covs = i
    # print(names(merged2)[n_covs])
    names1 = c(names1,names(merged2)[n_covs])
    temp = data.frame(trt = merged2$trt, merged2[,n_covs])
    temp = na.omit(temp)
    km_temp= kmeans(temp[,2:dim(temp)[2]], k, nstart = 20)
    vi1 = c(vi1, vi(cbind(temp$trt, km_temp$cluster))/(2*log(max(k,2))))
  }
  one_parameter = data.frame(names = names1, vi = vi1)
  print("**** min vi ****")
  print(min(one_parameter$vi))
  min_vi1 = c(min_vi1,min(one_parameter$vi))
  res = vi_selection(1,one_parameter,k)
  print("**** the summary table ****")
  print(cluster_summary_table(res$km,res$data))
  print("*** p value of the summary table ***")
  print(fisher.test(cluster_summary_table(res$km,res$data)[1:2,1:k])$p.value)
}

```


## Two variables

I then  chose two continuous variables and cluster subjects based on this variable into k groups (k = 2,3,...10). The results:

```{R echo = FALSE, comment=NA}

min_vi2 = c()
### two parameter
for(k in 2:10){
  # choose continuous variables
  
  print('************************************************************')
  print(paste('k = ',k))
  print('************************************************************')
  
  p = dim(merged)[2] 
  merged2 = merged
  covars = c()
  for(i in 2:p){
    if(class(merged[,i])=="integer" | class(merged[,i]) == "numeric"){
      if(length(unique(merged[,i]))>k){
        covars = c(covars, i)
      }
    }
  }
  merged2 = merged[,c(1,covars)]
  merged2$trt = merged$trt
  
  dim(merged2) # 150  47
  
  ## put into k-means and VI calculation
  
  names2 = c();
  vi2 = c()
  for(i in 2:(length(covars)-1)){
    for(j in (i+1):length(covars)){
      n_covs = c(i,j)
      #print(names(merged2)[n_covs])
      names2 = rbind(names2,names(merged2)[n_covs])
      temp = data.frame(trt = merged2$trt, merged2[,n_covs])
      #print("****")
      #print(dim(temp))
      temp = na.omit(temp)
      #print(dim(temp))
      km_temp= kmeans(temp[,2:dim(temp)[2]], k, nstart = 25)
      vi2 = c(vi2, vi(cbind(temp$trt, km_temp$cluster))/(2*log(max(k,2))))
      }
  }
  two_parameter = data.frame(names1 = names2[,1], names2 = names2[,2], vi = vi2)
  
  print("**** min vi ****")
  print(min(two_parameter$vi))
  res = vi_selection(1,two_parameter,k)
  min_vi2 = c(min_vi2,min(two_parameter$vi))
  print("**** the summary table ****")
  print(cluster_summary_table(res$km,res$data))
  print("*** p value of the summary table ***")
  print(fisher.test(cluster_summary_table(res$km,res$data)[1:2,1:k])$p.value)
}
```

#### The summary table


One variable

```{R echo = FALSE}
names(min_vi1) = 2:10
kable(round(t(min_vi1),3))
```

Two variables 

```{R echo = FALSE}
names(min_vi2) = 2:10
kable(round(t(min_vi2),3))
```

## When VI can be the max? 

Overall, it seems that, when the number of cluster matches, the VI can achive the max value. 